{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch # 파이토치 \nimport random\nimport numpy as np\nimport os\nimport torch.optim as optim\n# 시드값 고정\nseed = 42\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.enabled = False","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-11T06:57:38.621334Z","iopub.execute_input":"2023-01-11T06:57:38.621918Z","iopub.status.idle":"2023-01-11T06:57:38.635518Z","shell.execute_reply.started":"2023-01-11T06:57:38.621876Z","shell.execute_reply":"2023-01-11T06:57:38.634569Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-01-11T06:44:41.538530Z","iopub.execute_input":"2023-01-11T06:44:41.539512Z","iopub.status.idle":"2023-01-11T06:44:41.692375Z","shell.execute_reply.started":"2023-01-11T06:44:41.539459Z","shell.execute_reply":"2023-01-11T06:44:41.691306Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n\n# 데이터 경로\ndata_path = '/kaggle/input/plant-pathology-2020-fgvc7/'\n\ntrain = pd.read_csv(data_path + 'train.csv')\ntest = pd.read_csv(data_path + 'test.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')\nfrom sklearn.model_selection import train_test_split\n\n# 훈련 데이터, 검증 데이터 분리\ntrain, valid = train_test_split(train, \n                                test_size=0.1,\n                                stratify=train[['healthy', 'multiple_diseases', 'rust', 'scab']],\n                                random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T06:44:41.697234Z","iopub.execute_input":"2023-01-11T06:44:41.699658Z","iopub.status.idle":"2023-01-11T06:44:42.950998Z","shell.execute_reply.started":"2023-01-11T06:44:41.699616Z","shell.execute_reply":"2023-01-11T06:44:42.949792Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import cv2\nfrom torch.utils.data import Dataset # 데이터 생성을 위한 클래스\nimport numpy as np\n\nclass ImageDataset(Dataset):\n    # 초기화 메서드(생성자)\n    def __init__(self, df, img_dir='./', transform=None, is_test=False):\n        super().__init__() # 상속받은 Dataset의 __init__() 메서드 호출\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n\n    # 데이터셋 크기 반환 메서드 \n    def __len__(self):\n        return len(self.df)\n\n    # 인덱스(idx)에 해당하는 데이터 반환 메서드\n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0]             # 이미지 ID\n        img_path = self.img_dir + img_id + '.jpg' # 이미지 파일 경로\n        image = cv2.imread(img_path)              # 이미지 파일 읽기\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # 이미지 색상 보정\n        # 이미지 변환 \n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n        # 테스트 데이터면 이미지 데이터만 반환, 그렇지 않으면 타깃값도 반환 \n        if self.is_test:\n            return image # 테스트용일 때\n        else:\n            # 타깃값 4개 중 가장 큰 값의 인덱스 \n            label = np.argmax(self.df.iloc[idx, 1:5]) \n            return image, label # 훈련/검증용일 때","metadata":{"execution":{"iopub.status.busy":"2023-01-11T06:44:42.954368Z","iopub.execute_input":"2023-01-11T06:44:42.955026Z","iopub.status.idle":"2023-01-11T06:44:43.199682Z","shell.execute_reply.started":"2023-01-11T06:44:42.954983Z","shell.execute_reply":"2023-01-11T06:44:43.198637Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# 이미지 변환을 위한 모듈\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2","metadata":{"execution":{"iopub.status.busy":"2023-01-11T06:44:43.205113Z","iopub.execute_input":"2023-01-11T06:44:43.207511Z","iopub.status.idle":"2023-01-11T06:44:44.845707Z","shell.execute_reply.started":"2023-01-11T06:44:43.207471Z","shell.execute_reply":"2023-01-11T06:44:44.844572Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# 훈련 데이터용 변환기\ntransform_train = A.Compose([\n    A.Resize(450, 650),       # 이미지 크기 조절 \n    A.RandomBrightnessContrast(brightness_limit=0.2, # 밝기 대비 조절\n                               contrast_limit=0.2, p=0.3),\n    A.VerticalFlip(p=0.2),    # 상하 대칭 변환\n    A.HorizontalFlip(p=0.5),  # 좌우 대칭 변환 \n    A.ShiftScaleRotate(       # 이동, 스케일링, 회전 변환\n        shift_limit=0.1,\n        scale_limit=0.2,\n        rotate_limit=30, p=0.3),\n    A.OneOf([A.Emboss(p=1),   # 양각화, 날카로움, 블러 효과\n             A.Sharpen(p=1),\n             A.Blur(p=1)], p=0.3),\n    A.PiecewiseAffine(p=0.3), # 어파인 변환 \n    A.Normalize(),            # 정규화 변환 \n    ToTensorV2()              # 텐서로 변환\n])","metadata":{"execution":{"iopub.status.busy":"2023-01-11T06:44:44.847311Z","iopub.execute_input":"2023-01-11T06:44:44.847983Z","iopub.status.idle":"2023-01-11T06:44:44.858974Z","shell.execute_reply.started":"2023-01-11T06:44:44.847919Z","shell.execute_reply":"2023-01-11T06:44:44.857844Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# 검증 및 테스트 데이터용 변환기\ntransform_test = A.Compose([\n    A.Resize(450, 650), # 이미지 크기 조절 \n    A.Normalize(),      # 정규화 변환\n    ToTensorV2()        # 텐서로 변환\n])","metadata":{"execution":{"iopub.status.busy":"2023-01-11T06:44:44.860776Z","iopub.execute_input":"2023-01-11T06:44:44.861338Z","iopub.status.idle":"2023-01-11T06:44:44.872305Z","shell.execute_reply.started":"2023-01-11T06:44:44.861302Z","shell.execute_reply":"2023-01-11T06:44:44.871164Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"img_dir = '/kaggle/input/plant-pathology-2020-fgvc7/images/'\n\ndataset_train = ImageDataset(train, img_dir=img_dir, transform=transform_train)\ndataset_valid = ImageDataset(valid, img_dir=img_dir, transform=transform_test)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T06:44:44.873923Z","iopub.execute_input":"2023-01-11T06:44:44.874329Z","iopub.status.idle":"2023-01-11T06:44:44.884698Z","shell.execute_reply.started":"2023-01-11T06:44:44.874294Z","shell.execute_reply":"2023-01-11T06:44:44.883688Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\ng = torch.Generator()\ng.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T06:44:44.886851Z","iopub.execute_input":"2023-01-11T06:44:44.887304Z","iopub.status.idle":"2023-01-11T06:44:44.900356Z","shell.execute_reply.started":"2023-01-11T06:44:44.887259Z","shell.execute_reply":"2023-01-11T06:44:44.898164Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7f30e215ddb0>"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader # 데이터 로더 클래스\n\nbatch_size = 4\n\ntrainloader = DataLoader(dataset_train, batch_size=batch_size, \n                          shuffle=True, worker_init_fn=seed_worker,\n                          generator=g, num_workers=2)\nvalidloader = DataLoader(dataset_valid, batch_size=batch_size, \n                          shuffle=False, worker_init_fn=seed_worker,\n                          generator=g, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T06:44:44.904629Z","iopub.execute_input":"2023-01-11T06:44:44.904894Z","iopub.status.idle":"2023-01-11T06:44:44.912525Z","shell.execute_reply.started":"2023-01-11T06:44:44.904859Z","shell.execute_reply":"2023-01-11T06:44:44.911555Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!pip install efficientnet-pytorch==0.7.1\nfrom efficientnet_pytorch import EfficientNet # EfficientNet 모델\n# 사전 훈련된 efficientnet-b7 모델 불러오기\nmodel = EfficientNet.from_pretrained('efficientnet-b7', num_classes=4) \n\nmodel = model.to(device) # 장비 할당","metadata":{"execution":{"iopub.status.busy":"2023-01-11T06:44:44.914169Z","iopub.execute_input":"2023-01-11T06:44:44.914505Z","iopub.status.idle":"2023-01-11T06:45:16.605590Z","shell.execute_reply.started":"2023-01-11T06:44:44.914473Z","shell.execute_reply":"2023-01-11T06:45:16.604471Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Collecting efficientnet-pytorch==0.7.1\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.7.1) (1.11.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.1) (4.1.1)\nBuilding wheels for collected packages: efficientnet-pytorch\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=90a513bbd6d6e62f1a4ba7e9c6324227721ba49bf16df14e889f180bbb50d806\n  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\nSuccessfully built efficientnet-pytorch\nInstalling collected packages: efficientnet-pytorch\nSuccessfully installed efficientnet-pytorch-0.7.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b7-dcc49843.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/254M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b726dcdf9799436c9aca64b9e053f9cc"}},"metadata":{}},{"name":"stdout","text":"Loaded pretrained weights for efficientnet-b7\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn # 신경망 모듈\nfrom tqdm import tqdm\n# 손실 함수\ncriterion = nn.CrossEntropyLoss()\n\n# 옵티마이저\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.00006, weight_decay=0.0001) # 모델파라미터,러닝레이트,가중치\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=7, factor=0.1, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T06:57:58.987550Z","iopub.execute_input":"2023-01-11T06:57:58.988019Z","iopub.status.idle":"2023-01-11T06:57:59.010165Z","shell.execute_reply.started":"2023-01-11T06:57:58.987982Z","shell.execute_reply":"2023-01-11T06:57:59.009237Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def validation(model, validloader, criterion):\n  # 전방향 예측후 나온 점수(logits)의 최대값을 최종 예측으로 준비\n  # 이 최종 예측과 정답을 비교\n  # 전체 중 맞은 것의 개수 비율을 정확도(accuracy)로 계산\n  valid_accuracy = 0\n  valid_loss = 0\n\n  # 전방향 예측을 구할 때는 gradient가 필요가 없음\n  with torch.no_grad():\n    for images, labels in validloader: # 10000개의 데이터에 대해 16개씩(미니배치 사이즈) 10000/16번을 iterations\n      # 0. Data를 GPU로 보내기\n      images, labels = images.to(device), labels.to(device)\n\n      # 1. 입력데이터 준비\n      # not Flatten!!\n      # images.resize_(images.size()[0], 784) # 16, 1, 28, 28\n      \n      # 2. 전방향(Forward) 예측 \n      logits = model.forward(images) # 점수 반환\n      _, preds = torch.max(logits, 1) # 16개에 대한 최종 예측\n      # preds= probs.max(dim=1)[1] \n      correct = (preds == labels).sum()\n\n      accuracy = correct / images.shape[0]\n      loss = criterion(logits, labels) # 16개에 대한 loss\n      \n      valid_accuracy += accuracy\n      valid_loss += loss.item() # tensor 값을 꺼내옴\n    \n\n  return valid_loss, valid_accuracy # validloader 전체 대한 총 loss, 총 accuracy\n","metadata":{"execution":{"iopub.status.busy":"2023-01-11T06:45:16.621277Z","iopub.execute_input":"2023-01-11T06:45:16.621737Z","iopub.status.idle":"2023-01-11T06:45:16.632575Z","shell.execute_reply.started":"2023-01-11T06:45:16.621700Z","shell.execute_reply":"2023-01-11T06:45:16.631687Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from torch.utils.tensorboard import SummaryWriter\n\nwriter  = SummaryWriter()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T06:45:16.634580Z","iopub.execute_input":"2023-01-11T06:45:16.635007Z","iopub.status.idle":"2023-01-11T06:45:21.559016Z","shell.execute_reply.started":"2023-01-11T06:45:16.634959Z","shell.execute_reply":"2023-01-11T06:45:21.557909Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def train(model, epochs, criterion, optimizer):\n  steps = 0\n  min_loss = 10000\n  max_accuracy = 0\n\n  trigger = 0\n  patience = 13 # for Early stopping\n\n  # 1 에폭(epoch)당 반복수\n  #steps_per_epoch = len(trainset)/batch_size # 2500 iterations\n  steps_per_epoch = len(trainloader) # 2500 iterations\n\n  for epoch in range(epochs):\n    model.train()\n    train_loss = 0\n    for images, labels in tqdm(trainloader): # 이터레이터로부터 미니배치 16개씩을 가져와 images, labels에 준비\n      steps += 1\n      # 0. Data를 GPU로 보내기\n      images, labels = images.to(device), labels.to(device)\n\n      # 1. 입력 데이터 준비\n      # not Flatten!!\n      # images.resize_(images.size()[0], 784) # 16, 1, 28, 28\n\n      # 2. 전방향(Forward) 예측 \n      outputs = model.forward(images) # 예측\n      loss = criterion(outputs, labels) # 예측과 결과를 통해 Cross Entropy Loss 반환\n\n      # 3. 역방향(Backward) 오차(Gradient) 전파\n      optimizer.zero_grad() # 파이토치에서 gradient가 누적되지 않게 하기 위해\n      loss.backward()\n\n      # 4. 경사하강법으로 모델 파라미터 업데이트\n      optimizer.step() # W <- W -lr*Gradient\n\n      train_loss += loss.item()\n      if (steps % steps_per_epoch) == 0: # step : 2500, .... (epoch 마다)\n        model.eval() # 배치 정규화, 드롭아웃이 적용될 때는 model.forward 연산이 training때와 다르므로 반드시 설정\n        valid_loss, valid_accuracy = validation(model, validloader, criterion)\n\n        # tensorboad 시각화를 위한 로그 이벤트 등록\n        writer.add_scalar(\"Loss/train\", train_loss/len(trainloader), epoch)\n        writer.add_scalar(\"Loss/valid\", valid_loss/len(validloader), epoch)\n        writer.add_scalars(\"Loss/train and valid\",\n                          {'train' : train_loss/len(trainloader),\n                          'valid' : valid_loss/len(validloader)}, epoch)\n        \n        writer.add_scalar(\"Valid Accuracy\", valid_accuracy/len(validloader), epoch)\n\n\n        print('Epoch : {}/{}.....'.format(epoch+1, epochs),\n              'Train Loss : {:.3f}'.format(train_loss/len(trainloader)),\n              'Valid Loss : {:.3f}'.format(valid_loss/len(validloader)),\n              'Valid Accuracy : {:.3f}'.format(valid_accuracy/len(validloader)))\n        \n        # Best model 저장\n        # option 1\n        # if valid_loss < min_loss:\n        #   min_loss = valid_loss\n        #   torch.save(model.state_dict(), 'best_checkpoint.pth')\n\n        # option 2\n        if valid_accuracy > max_accuracy: \n          max_accuracy = valid_accuracy\n          torch.save(model.state_dict(), 'best_checkpoint.pth')\n\n        # Early Stopping (조기 종료)\n        if valid_loss > min_loss:\n          trigger += 1 # valid loss가 min_loss 를 갱신하지 못할때마다 증가\n          print('trigger : ', trigger )\n          if trigger > patience:\n            print('Early Stopping!!!')\n            print('Traning step is finished!!')\n            writer.flush()  \n            return   \n        else:\n          trigger = 0\n          min_loss = valid_loss\n\n\n        train_loss = 0\n        model.train()\n\n        # Learning Rate Scheduler\n        scheduler.step(valid_loss)\n\n  writer.flush()      ","metadata":{"execution":{"iopub.status.busy":"2023-01-11T06:45:21.561110Z","iopub.execute_input":"2023-01-11T06:45:21.561762Z","iopub.status.idle":"2023-01-11T06:45:21.577565Z","shell.execute_reply.started":"2023-01-11T06:45:21.561723Z","shell.execute_reply":"2023-01-11T06:45:21.576171Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"epochs=15\ntrain(model, epochs, criterion, optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T06:58:12.173445Z","iopub.execute_input":"2023-01-11T06:58:12.173871Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"100%|█████████▉| 409/410 [08:01<00:01,  1.17s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch : 1/15..... Train Loss : 0.369 Valid Loss : 0.271 Valid Accuracy : 0.940\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [08:17<00:00,  1.21s/it]\n 43%|████▎     | 178/410 [03:30<04:31,  1.17s/it]","output_type":"stream"}]},{"cell_type":"code","source":"%load_ext tensorboard","metadata":{"execution":{"iopub.status.busy":"2023-01-11T06:53:43.203102Z","iopub.status.idle":"2023-01-11T06:53:43.203879Z","shell.execute_reply.started":"2023-01-11T06:53:43.203608Z","shell.execute_reply":"2023-01-11T06:53:43.203638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%tensorboard --logdir=runs","metadata":{"execution":{"iopub.status.busy":"2023-01-11T06:53:43.205253Z","iopub.status.idle":"2023-01-11T06:53:43.205957Z","shell.execute_reply.started":"2023-01-11T06:53:43.205707Z","shell.execute_reply":"2023-01-11T06:53:43.205731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 테스트 데이터 원본 데이터셋 및 데이터 로더\ndataset_test = ImageDataset(test, img_dir=img_dir, \n                            transform=transform_test, is_test=True)\nloader_test = DataLoader(dataset_test, batch_size=batch_size, \n                         shuffle=False, worker_init_fn=seed_worker,\n                         generator=g, num_workers=2)\n\n# TTA용 데이터셋 및 데이터 로더\ndataset_TTA = ImageDataset(test, img_dir=img_dir, \n                           transform=transform_train, is_test=True)\nloader_TTA = DataLoader(dataset_TTA, batch_size=batch_size, \n                        shuffle=False, worker_init_fn=seed_worker,\n                        generator=g, num_workers=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_tta = submission.copy() \n\nsubmission_tta[['healthy', 'multiple_diseases', 'rust', 'scab']] = preds_tta","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_test.to_csv('submission_test.csv', index=False)\nsubmission_tta.to_csv('submission_tta.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_label_smoothing(df, target, alpha, threshold):\n    # 타깃값 복사\n    df_target = df[target].copy()\n    k = len(target) # 타깃값 개수\n\n    for idx, row in df_target.iterrows():\n        if (row > threshold).any():         # 임계값을 넘는 타깃값인지 여부 판단\n            row = (1 - alpha)*row + alpha/k # 레이블 스무딩 적용  \n            df_target.iloc[idx] = row       # 레이블 스무딩을 적용한 값으로 변환\n    return df_target # 레이블 스무딩을 적용한 타깃값 반환","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alpha = 0.001 # 레이블 스무딩 강도\nthreshold = 0.999 # 레이블 스무딩을 적용할 임계값\n\n# 레이블 스무딩을 적용하기 위해 DataFrame 복사\nsubmission_test_ls = submission_test.copy()\nsubmission_tta_ls = submission_tta.copy()\n\ntarget = ['healthy', 'multiple_diseases', 'rust', 'scab'] # 타깃값 열 이름\n\n# 레이블 스무딩 적용\nsubmission_test_ls[target] = apply_label_smoothing(submission_test_ls, target, \n                                                   alpha, threshold)\nsubmission_tta_ls[target] = apply_label_smoothing(submission_tta_ls, target, \n                                                  alpha, threshold)\n\nsubmission_test_ls.to_csv('submission_test_ls.csv', index=False)\nsubmission_tta_ls.to_csv('submission_tta_ls.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}